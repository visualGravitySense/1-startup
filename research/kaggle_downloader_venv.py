#!/usr/bin/env python3
"""
Kaggle Dataset Downloader for Educational Platform Research (Virtual Environment Version)
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å Kaggle —á–µ—Ä–µ–∑ Python API
"""

import os
import sys
from pathlib import Path
import zipfile
import tempfile

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
DATA_DIR = Path("data")
RAW_DATA_DIR = DATA_DIR / "raw"
PROCESSED_DATA_DIR = DATA_DIR / "processed"

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
for dir_path in [DATA_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR]:
    dir_path.mkdir(exist_ok=True)

# –°–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ research-plan.md
DATASETS = {
    # 1. –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    "education": [
        "deviakumbach/student-performance-data",  # Student Performance
        "whenamancodes/students-performance-in-exams",  # Exam Performance
        "spscientist/students-performance-in-exams",  # Academic Performance
        "larsen0966/student-performance-data-set",  # Learning Analytics
        "aljarah/xAPI-Edu-Data",  # Educational Process Mining
        "uciml/student-performance-data-set",  # UCI Student Performance
    ],
    
    # 2. –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –Ω–∞–≤—ã–∫–∏
    "job_market": [
        "promptcloud/jobs-on-naukricom",  # Job Market Analysis
        "rkiattisak/salaly-prediction-for-beginer",  # Salary Prediction
        "andrewmvd/data-scientist-jobs",  # Data Science Jobs
        "arshkon/linkedin-job-postings",  # LinkedIn Jobs
        "lukebarousse/data-analyst-job-postings-google-search",  # Job Postings
    ],
    
    # 3. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã
    "tech_trends": [
        "stackoverflow/stack-overflow-2022-developers-survey",  # Developer Survey
        "kaggle/kaggle-survey-2022",  # ML & DS Survey
        "stackoverflow/stackoverflow-developer-survey-2023",  # Latest Developer Trends
        "kaggle/state-of-data-science-and-machine-learning-2023",  # Data Science Trends
    ],
    
    # 4. –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    "demographics": [
        "kaggle/meta-kaggle",  # Kaggle User Behavior
        "datasnaek/youtube-new",  # Online Learning Behavior
        "Cornell-University/arxiv",  # Academic Research Trends
        "rounakbanik/the-movies-dataset",  # Content Preferences
    ]
}

def check_kaggle_api():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Kaggle API"""
    try:
        from kaggle.api.kaggle_api_extended import KaggleApi
        api = KaggleApi()
        api.authenticate()
        print("‚úÖ Kaggle API –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return api
    except ImportError:
        print("‚ùå Kaggle –ø–∞–∫–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Kaggle API: {e}")
        print("\nüí° –î–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API:")
        print("1. –ó–∞–π–¥–∏—Ç–µ –Ω–∞ https://www.kaggle.com/settings/account")
        print("2. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API —Ç–æ–∫–µ–Ω")
        print("3. –°–∫–∞—á–∞–π—Ç–µ kaggle.json")
        print("4. –ü–æ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª –≤ %USERPROFILE%\\.kaggle\\kaggle.json")
        return None

def download_dataset_api(api, dataset_name, category):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ Kaggle API"""
    category_dir = RAW_DATA_DIR / category
    category_dir.mkdir(exist_ok=True)
    
    dataset_dir = category_dir / dataset_name.replace("/", "_")
    
    if dataset_dir.exists() and any(dataset_dir.iterdir()):
        print(f"‚è≠Ô∏è  –î–∞—Ç–∞—Å–µ—Ç {dataset_name} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
        return True
    
    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º {dataset_name}...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        with tempfile.TemporaryDirectory() as temp_dir:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            api.dataset_download_files(dataset_name, path=temp_dir, unzip=True)
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            dataset_dir.mkdir(exist_ok=True)
            temp_path = Path(temp_dir)
            
            for file_path in temp_path.iterdir():
                if file_path.is_file():
                    target_path = dataset_dir / file_path.name
                    file_path.rename(target_path)
                elif file_path.is_dir():
                    # –ö–æ–ø–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
                    import shutil
                    shutil.copytree(file_path, dataset_dir / file_path.name, dirs_exist_ok=True)
        
        print(f"‚úÖ {dataset_name} –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {dataset_name}: {e}")
        return False

def create_dataset_info():
    """–°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö"""
    info_content = """# –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### 1. –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (education/)
- –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
- –§–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ
- –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –æ–±—É—á–µ–Ω–∏–∏

### 2. –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (job_market/)
- –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
- –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ –Ω–∞–≤—ã–∫–∞–º
- –¢—Ä–µ–Ω–¥—ã –≤ –Ω–∞–π–º–µ

### 3. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã (tech_trends/)
- –û–ø—Ä–æ—Å—ã —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
- –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è –∏–Ω–¥—É—Å—Ç—Ä–∏–∏

### 4. –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (demographics/)
- –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–Ω–ª–∞–π–Ω-–ø–ª–∞—Ç—Ñ–æ—Ä–º
- –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏
- –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

–í—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ `data/raw/` –∏ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.
–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `data/processed/`.

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
2. –û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
3. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA)
4. –í—ã—è–≤–ª–µ–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞

## –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã

"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
    for category, datasets in DATASETS.items():
        info_content += f"\n### {category.title()}\n"
        for dataset in datasets:
            dataset_dir = RAW_DATA_DIR / category / dataset.replace("/", "_")
            status = "‚úÖ" if dataset_dir.exists() and any(dataset_dir.iterdir()) else "‚ùå"
            info_content += f"- {status} {dataset}\n"
    
    with open(DATA_DIR / "README.md", "w", encoding="utf-8") as f:
        f.write(info_content)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É Kaggle –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Kaggle API
    api = check_kaggle_api()
    if not api:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Kaggle API")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª
    create_dataset_info()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    total_datasets = sum(len(datasets) for datasets in DATASETS.values())
    downloaded = 0
    failed = 0
    
    for category, datasets in DATASETS.items():
        print(f"\nüìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
        print("-" * 40)
        
        for dataset in datasets:
            if download_dataset_api(api, dataset, category):
                downloaded += 1
            else:
                failed += 1
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    create_dataset_info()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–ò –ó–ê–ì–†–£–ó–ö–ò:")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {downloaded}/{total_datasets}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {failed}/{total_datasets}")
    
    if failed > 0:
        print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –æ—à–∏–±–æ–∫:")
        print("- –î–∞—Ç–∞—Å–µ—Ç —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–Ω—è—Ç–∏—è —É—Å–ª–æ–≤–∏–π –Ω–∞ Kaggle")
        print("- –î–∞—Ç–∞—Å–µ—Ç –±—ã–ª —É–¥–∞–ª–µ–Ω –∏–ª–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω")
        print("- –ü—Ä–æ–±–ª–µ–º—ã —Å API –∫–ª—é—á–æ–º Kaggle")
        print("- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É")
    
    print(f"\nüìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {DATA_DIR.absolute()}")
    print("üìñ –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤: data/README.md")

if __name__ == "__main__":
    main() 